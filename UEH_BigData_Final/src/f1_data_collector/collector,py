"""
Optimized F1 Data Collector with Enhanced Error Handling
"""

import fastf1
import pandas as pd
from pathlib import Path
from typing import Optional, Tuple, Dict, Any
from retry import retry
import logging
from src.config import settings
from data.utils import DataUtils
from config.settings import ProjectConfig

logging.basicConfig(level=settings.LOG_LEVEL)
logger = logging.getLogger(__name__)

class F1DataCollector:
    """High-reliability data collector with Spark-compatible outputs"""
    
    def __init__(self):
        self.config = ProjectConfig()
        self._season_schemas = DataUtils.load_json_config(
            self.config.SCHEMA_CONFIG_PATH / "f1_raw_schema.json"
        )
        
    @retry(exceptions=Exception, 
           tries=settings.F1_API_RETRY_CONFIG["max_retries"],
           delay=settings.F1_API_RETRY_CONFIG["delay"],
           backoff=settings.F1_API_RETRY_CONFIG["backoff"],
           logger=logger)
    def _load_session(self, year: int, event_name: str, session_type: str) -> Optional[fastf1.core.Session]:
        """Tải session data với cơ chế retry thông minh"""
        try:
            session = fastf1.get_session(year, event_name, session_type)
            session.load()
            
            if not self._validate_session_data(session):
                raise ValueError("Invalid session data structure")
                
            logger.debug(f"Loaded {session_type} session for {event_name} {year}")
            return session
            
        except Exception as e:
            logger.error(f"Session load failed: {str(e)}")
            return None

    def _validate_session_data(self, session: fastf1.core.Session) -> bool:
        """Kiểm tra chất lượng dữ liệu session theo tiêu chuẩn"""
        required_attributes = ['laps', 'results', 'weather_data']
        return all(hasattr(session, attr) for attr in required_attributes)

    def _process_laps(self, session: fastf1.core.Session) -> pd.DataFrame:
        """Chuẩn hóa và làm sạch lap data"""
        try:
            # Áp dụng schema validation
            laps_df = session.laps[self._season_schemas["lap_columns"]]
            
            # Chuyển đổi định dạng thời gian
            time_columns = ['LapTime', 'Sector1Time', 'Sector2Time', 'Sector3Time']
            laps_df[time_columns] = laps_df[time_columns].apply(lambda x: x.dt.total_seconds())
            
            # Thêm metadata
            laps_df['season'] = session.event.year
            laps_df['event_name'] = session.event.EventName
            
            return laps_df
            
        except KeyError as e:
            logger.error(f"Missing required columns: {str(e)}")
            raise
        except Exception as e:
            logger.error(f"Lap processing failed: {str(e)}")
            raise

    def _generate_output_path(self, year: int, event_name: str, session_type: str) -> Path:
        """Tạo đường dẫn file đầu ra theo CCDS standard"""
        sanitized_name = DataUtils.sanitize_filename(event_name)
        return Path(
            self.config.RAW_DATA_DIR,
            f"year={year}",
            f"{sanitized_name}_{session_type}.parquet"
        )

    def collect_event_data(self, year: int, event_name: str) -> Dict[str, Path]:
        """Pipeline chính cho thu thập dữ liệu một sự kiện"""
        result_paths = {}
        
        for session_type in ['R', 'Q']:
            if session := self._load_session(year, event_name, session_type):
                try:
                    processed_data = self._process_laps(session)
                    output_path = self._generate_output_path(year, event_name, session_type)
                    
                    # Validate và lưu data
                    if DataUtils.validate_data_stats(processed_data, self.config.MIN_RECORDS_PER_FILE):
                        DataUtils.write_parquet(
                            processed_data, 
                            str(output_path),
                            partition_cols=['season']
                        )
                        result_paths[session_type] = output_path
                        
                except Exception as e:
                    logger.error(f"Failed to process {session_type} data: {str(e)}")
                    continue
                    
        return result_paths

    def run_season_collection(self, years: Optional[List[int]] = None) -> Dict[int, Dict]:
        """Orchestration layer cho thu thập theo mùa giải"""
        results = {}
        target_years = years or self.config.SEASONS
        
        for year in target_years:
            logger.info(f"Starting collection for {year} season")
            schedule = fastf1.get_event_schedule(year)
            valid_events = self._filter_official_events(schedule)
            
            year_results = {}
            for _, event in valid_events.iterrows():
                event_name = event['EventName']
                year_results[event_name] = self.collect_event_data(year, event_name)
                
            results[year] = year_results
            
        return results

    def _filter_official_events(self, schedule: pd.DataFrame) -> pd.DataFrame:
        """Lọc các sự kiện chính thức theo tiêu chí"""
        return schedule[
            (schedule['EventFormat'] == 'conventional') &
            (~schedule['EventName'].str.contains('Test|Sprint', case=False)) &
            (schedule['EventDate'] < pd.Timestamp.now())  # Chỉ sự kiện đã diễn ra
        ]
